# Presentation for a paper about GPU

Parallel and accurate k-means algorithm on CPU-GPU architectures for spectral clustering

<https://onlinelibrary.wiley.com/doi/10.1002/cpe.6621>

---

- [Presentation for a paper about GPU](#presentation-for-a-paper-about-gpu)
  - [Summary](#summary)
  - [Contents](#contents)
    - [1. Introduction](#1-introduction)
      - [Notation - Table #1](#notation---table-1)
    - [2. A computational chain for spectral clustering](#2-a-computational-chain-for-spectral-clustering)
      - [2.1. Background for spectral clustering](#21-background-for-spectral-clustering)
      - [2.2. k-Means algorithm](#22-k-means-algorithm)
      - [2.3. Hybrid CPU-GPU complete processing chain](#23-hybrid-cpu-gpu-complete-processing-chain)
    - [3. Optimizing parallel k-Means algorithm](#3-optimizing-parallel-k-means-algorithm)
      - [3.1. Parallel implementation strategies](#31-parallel-implementation-strategies)
      - [3.2. ComputeAssign routine](#32-computeassign-routine)
      - [3.3. Update routine](#33-update-routine)
        - [3.3.1. Effect of rounding errors](#331-effect-of-rounding-errors)
        - [3.3.2. Two-step method with package processing](#332-two-step-method-with-package-processing)
    - [4. Experimental evaluation](#4-experimental-evaluation)
      - [4.1. Experiments on synthetic dataset](#41-experiments-on-synthetic-dataset)
      - [4.2. Experiments on real-world datasets](#42-experiments-on-real-world-datasets)
      - [4.3. Comparison with other recent parallel k-means implementations](#43-comparison-with-other-recent-parallel-k-means-implementations)
    - [5. Conclusion](#5-conclusion)
  - [Presentation plan](#presentation-plan)
    - [~~Subject(key points) to explain...~~ Split into 3](#subjectkey-points-to-explain-split-into-3)

---

## Summary

- In common, k-means is used for spectral clustering
- When dataset is large, the process suffers from lack of scalability
- To solve that, preprocessing the data with k-means can reduce the input data.
- This paper provides: Parallel optimization tech for k-means on CPU, GPU

## Contents

### 1. Introduction

- Clustering
  - means Grouping similar data into subset
  - is Important tasks in unsupervised ML and data mining
  - Has many applications
- k-means
  - Distance-based method
  - Effective in finding convex clusters, but not nonconvex clusters
    > Example drawing of Convex cluster and non-convex cluster
    > ![img](https://i.stack.imgur.com/P7XOP.png)
    > <https://math.stackexchange.com/questions/2751592/what-defines-a-convex-cluster-and-how-it-differentiates-from-other-types>
  - Selection of initial cluster centroids is important to avoid some problems
- Spectral clustering
  - Based on Graph theory
  - Has advantages over k-means:
- Implementation with HPC(High Performance Computer)
- Scalability
- Optimize CPU and GPU
- Contents
  - 2 = Classical method of spectral clustering, heterogeneous CPU-GPU-based computational chain
  - 3 = Parallel implementations of k-means on CPU, GPU with optimizations
  - 4 = Experiment results
  - 5 = Conclusion

#### Notation - Table #1

| Notation | Meaning                                  |
| -------- | ---------------------------------------- |
| $n$      | Number of data instances                 |
| $n_d$    | Number of dimensions for each instance   |
| $k_c$    | Number of desired clusters               |
| $k_r$    | Number of _representatives_              |
| $x_i$    | Data instance $i$                        |
| $s_{ij}$ | Similarity between instances $i$ and $j$ |

### 2. A computational chain for spectral clustering

- k-means
- CPU-GPU processing chain for spectral clustering

#### 2.1. Background for spectral clustering

- Explains How to
  - Represent data instances as a graph
  - Represent the graph as a matrix, which is "graph Laplacian"
    > Laplacian matrix = Adjacent matrix

#### 2.2. k-Means algorithm

#### 2.3. Hybrid CPU-GPU complete processing chain

### 3. Optimizing parallel k-Means algorithm

- 2 parallel/optimized implementation of the k-means on CPU, GPU
  - Including: inherent bottlenecks, suggested optimization methods in updating centroid

#### 3.1. Parallel implementation strategies

"OpenMP", "CUDA", "cuBLAS" library, something something...

#### 3.2. ComputeAssign routine

#### 3.3. Update routine

##### 3.3.1. Effect of rounding errors

##### 3.3.2. Two-step method with package processing

### 4. Experimental evaluation

#### 4.1. Experiments on synthetic dataset

#### 4.2. Experiments on real-world datasets

#### 4.3. Comparison with other recent parallel k-means implementations

### 5. Conclusion

---

## Presentation plan

### ~~Subject(key points) to explain...~~ Split into 3

- Theory (Hard part)
    1. Spectral clustering ([2.1.](#21-background-for-spectral-clustering))
    2. k-Means ([2.2.](#22-k-means-algorithm))
    3. Hybrid CPU-GPU complete processing chain ([2.3.](#23-hybrid-cpu-gpu-complete-processing-chain))
- Practical (Long part)
  - Bunch of codes...
- Experiment and result, conclusion (Maybe easy, but quite important)
  - Bunch of tables and numbers...
